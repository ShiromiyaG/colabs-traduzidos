{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwZHPNs5tYAW"
      },
      "source": [
        "# **RVC-CLI para treino (Versão simplificada)**\n",
        "Criado por [ShiromiyaG](https://github.com/ShiromiyaG)\n",
        "- Usa o [Applio](https://github.com/IAHispano/Applio) do [IAHispano](https://github.com/IAHispano)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r4TIXgsdswsO"
      },
      "outputs": [],
      "source": [
        "#@title # **Instalar**\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!git clone https://github.com/IAHispano/Applio.git --branch 3.2.2 --single-branch\n",
        "%cd /content/Applio\n",
        "rot_47 = lambda encoded_text: \"\".join(\n",
        "    [\n",
        "        (\n",
        "            chr(\n",
        "                (ord(c) - (ord(\"a\") if c.islower() else ord(\"A\")) - 47) % 26\n",
        "                + (ord(\"a\") if c.islower() else ord(\"A\"))\n",
        "            )\n",
        "            if c.isalpha()\n",
        "            else c\n",
        "        )\n",
        "        for c in encoded_text\n",
        "    ]\n",
        ")\n",
        "import codecs\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "E = Exception\n",
        "B = print\n",
        "\n",
        "\n",
        "def vidal_setup(ForceIn):\n",
        "    L = \"Kikpm.ovm.bu\"\n",
        "    K = \"/content/\"\n",
        "    C = ForceIn\n",
        "\n",
        "    def F():\n",
        "        print(\"Installing pip packages...\")\n",
        "        subprocess.check_call([\"pip\", \"install\", \"-r\", \"requirements.txt\", \"--quiet\"])\n",
        "\n",
        "    A = K + rot_47(L)\n",
        "    G = K + rot_47(L)\n",
        "    D = \"/\"\n",
        "    if not os.path.exists(A):\n",
        "        M = os.path.dirname(A)\n",
        "        os.makedirs(M, exist_ok=True)\n",
        "        print(\"No cached install found..\")\n",
        "        try:\n",
        "            N = rot_47(\n",
        "                codecs.decode(\n",
        "                    \"pbbxa://pcooqvonikm.kw/QIPqaxivw/Ixxtqw/zmawtdm/uiqv/Kwtij/Xvxcz.biz.oh\",\n",
        "                    \"rot_13\",\n",
        "                )\n",
        "            )\n",
        "            subprocess.run([\"wget\", \"-O\", A, N])\n",
        "            print(\"Download completed successfully!\")\n",
        "        except E as H:\n",
        "            print(str(H))\n",
        "            if os.path.exists(A):\n",
        "                os.remove(A)\n",
        "    if Path(A).exists():\n",
        "        with tarfile.open(G, \"r:gz\") as I:\n",
        "            for J in I.getmembers():\n",
        "                O = os.path.join(D, J.name)\n",
        "                try:\n",
        "                    I.extract(J, D)\n",
        "                except E as H:\n",
        "                    print(\"Failed to extract a file\")\n",
        "                    C = True\n",
        "            print(f\"Extraction of {G} to {D} completed.\")\n",
        "        if os.path.exists(A):\n",
        "            os.remove(A)\n",
        "        if C:\n",
        "            F()\n",
        "            C = False\n",
        "    else:\n",
        "        F()\n",
        "\n",
        "\n",
        "vidal_setup(False)\n",
        "!python core.py prerequisites --pretraineds_v1 \"False\" --pretraineds_v2 \"True\" --models \"True\" --exe \"False\"\n",
        "print(\"Finished installing requirements!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPbIgW09yT_Y"
      },
      "source": [
        "# **Treino**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xVjT6nYLyYan"
      },
      "outputs": [],
      "source": [
        "#@title ### Preprocessar dataset e Extract Features\n",
        "# @markdown ### ➡️ Informações do modelo\n",
        "nome_do_modelo = \"\" # @param {type:\"string\"}\n",
        "#@markdown ##### **Caminho da pasta no seu drive**\n",
        "caminho_para_o_dataset = \"rvc-cli/nome-do-dataset\"  # @param {type:\"string\"}\n",
        "caminho_completo = \"/content/drive/MyDrive/\" + caminho_para_o_dataset\n",
        "sample_rate = 32000 # @param [32000, 40000, 48000] {allow-input: false}\n",
        "cpu_cores = 2\n",
        "!python core.py preprocess --model_name \"{nome_do_modelo}\" --dataset_path \"{caminho_completo}\" --sample_rate \"{sample_rate}\" --cpu_cores \"{cpu_cores}\"\n",
        "versao_do_rvc = \"v2\"  # @param [\"v2\", \"v1\"] {allow-input: false}\n",
        "metodo_do_f0 = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\"] {allow-input: false}\n",
        "orientação_de_pitch = True  # @param{type:\"boolean\"}\n",
        "tamanho_do_hop = 128  # @param {type:\"slider\", min:1, max:512, step:0}\n",
        "\n",
        "!python core.py extract --model_name \"{nome_do_modelo}\" --rvc_version \"{versao_do_rvc}\" --f0_method \"{metodo_do_f0}\" --pitch_guidance \"{orientação_de_pitch}\" --hop_length \"{tamanho_do_hop}\" --sample_rate \"{sample_rate}\" --cpu_cores \"{cpu_cores}\" --gpu \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n21oINoI0sOu"
      },
      "outputs": [],
      "source": [
        "# @title ### Treino\n",
        "# @markdown ### ➡️ Informações do modelo\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import hashlib\n",
        "import time\n",
        "\n",
        "LOGS_FOLDER = \"/content/Applio/logs/\"\n",
        "WEIGHTS_FOLDER = LOGS_FOLDER + nome_do_modelo\n",
        "GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive/RVC_Backup\"\n",
        "\n",
        "\n",
        "def import_google_drive_backup():\n",
        "    print(\"Importando dataset do Google Drive...\")\n",
        "    weights_exist = False\n",
        "    for root, dirs, files in os.walk(GOOGLE_DRIVE_PATH):\n",
        "        for filename in files:\n",
        "            filepath = os.path.join(root, filename)\n",
        "            if os.path.isfile(filepath) and not filepath.startswith(\n",
        "                os.path.join(GOOGLE_DRIVE_PATH, \"weights\")\n",
        "            ):\n",
        "                backup_filepath = os.path.join(\n",
        "                    LOGS_FOLDER, os.path.relpath(filepath, GOOGLE_DRIVE_PATH)\n",
        "                )\n",
        "                backup_folderpath = os.path.dirname(backup_filepath)\n",
        "                if not os.path.exists(backup_folderpath):\n",
        "                    os.makedirs(backup_folderpath)\n",
        "                    print(f\"Criar pasta de backup: {backup_folderpath}\", flush=True)\n",
        "                shutil.copy2(filepath, backup_filepath)  # copy file with metadata\n",
        "                print(f\"Importar arquivo de backup do Google Drive: {filename}\")\n",
        "            elif filepath.startswith(\n",
        "                os.path.join(GOOGLE_DRIVE_PATH, \"weights\")\n",
        "            ) and filename.endswith(\".pth\"):\n",
        "                weights_exist = True\n",
        "                weights_filepath = os.path.join(\n",
        "                    WEIGHTS_FOLDER,\n",
        "                    os.path.relpath(\n",
        "                        filepath, os.path.join(GOOGLE_DRIVE_PATH, \"weights\")\n",
        "                    ),\n",
        "                )\n",
        "                weights_folderpath = os.path.dirname(weights_filepath)\n",
        "                if not os.path.exists(weights_folderpath):\n",
        "                    os.makedirs(weights_folderpath)\n",
        "                    print(f\"Criar pasta dos weights: {weights_folderpath}\", flush=True)\n",
        "                shutil.copy2(filepath, weights_filepath)  # copy file with metadata\n",
        "                print(f\"Importar arquivo de weights: {filename}\")\n",
        "    if weights_exist:\n",
        "        print(\"Copiado os weights do Google Drive para pasta de weights local.\")\n",
        "    else:\n",
        "        print(\"Nenhum weights encontrado no backup do Google Drive.\")\n",
        "    print(\"Importação do backup do Google Drive concluída.\")\n",
        "\n",
        "\n",
        "def get_md5_hash(file_path):\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "\n",
        "def copy_weights_folder_to_drive():\n",
        "    destination_folder = os.path.join(GOOGLE_DRIVE_PATH, \"weights\")\n",
        "    try:\n",
        "        if not os.path.exists(destination_folder):\n",
        "            os.makedirs(destination_folder)\n",
        "\n",
        "        num_copied = 0\n",
        "        for filename in os.listdir(WEIGHTS_FOLDER):\n",
        "            if filename.endswith(\".pth\"):\n",
        "                source_file = os.path.join(WEIGHTS_FOLDER, filename)\n",
        "                destination_file = os.path.join(destination_folder, filename)\n",
        "                if not os.path.exists(destination_file):\n",
        "                    shutil.copy2(source_file, destination_file)\n",
        "                    num_copied += 1\n",
        "                    print(f\"{filename} copiado para o Google Drive!\")\n",
        "\n",
        "        if num_copied == 0:\n",
        "            print(\"Não foram encontrados novos modelos acabados para copiar.\")\n",
        "        else:\n",
        "            print(f\"Terminou a cópia de {num_copied} arquivos para o Google Drive!\")\n",
        "\n",
        "    except Exception as error:\n",
        "        print(f\"Ocorreu um erro durante a cópia de pesos para o Google Drive: {str(error)}\")\n",
        "\n",
        "\n",
        "if \"autobackups\" not in globals():\n",
        "    autobackups = False\n",
        "\n",
        "\n",
        "def backup_files():\n",
        "    print(\"\\nComeçando loop de backups...\")\n",
        "    last_backup_timestamps_path = os.path.join(\n",
        "        LOGS_FOLDER, \"last_backup_timestamps.txt\"\n",
        "    )\n",
        "    fully_updated = False\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            updated = False\n",
        "            last_backup_timestamps = {}\n",
        "\n",
        "            try:\n",
        "                with open(last_backup_timestamps_path, \"r\") as f:\n",
        "                    last_backup_timestamps = dict(line.strip().split(\":\") for line in f)\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "            for root, dirs, files in os.walk(LOGS_FOLDER):\n",
        "                # Excluding \"zips\" directory\n",
        "                if \"zips\" in dirs:\n",
        "                    dirs.remove(\"zips\")\n",
        "                if \"mute\" in dirs:\n",
        "                    dirs.remove(\"mute\")\n",
        "                print(\"Criando backup de arquivos, espere\")\n",
        "                for filename in files:\n",
        "                    if filename != \"last_backup_timestamps.txt\":\n",
        "                        filepath = os.path.join(root, filename)\n",
        "                        if os.path.isfile(filepath):\n",
        "                            backup_filepath = os.path.join(\n",
        "                                GOOGLE_DRIVE_PATH,\n",
        "                                os.path.relpath(filepath, LOGS_FOLDER),\n",
        "                            )\n",
        "                            backup_folderpath = os.path.dirname(backup_filepath)\n",
        "                            if not os.path.exists(backup_folderpath):\n",
        "                                os.makedirs(backup_folderpath)\n",
        "                                print(\n",
        "                                    f\"Criado pasta de backups: {backup_folderpath}\",\n",
        "                                    flush=True,\n",
        "                                )\n",
        "                            last_backup_timestamp = last_backup_timestamps.get(filepath)\n",
        "                            current_timestamp = os.path.getmtime(filepath)\n",
        "                            if (\n",
        "                                last_backup_timestamp is None\n",
        "                                or float(last_backup_timestamp) < current_timestamp\n",
        "                            ):\n",
        "                                shutil.copy2(filepath, backup_filepath)\n",
        "                                last_backup_timestamps[filepath] = str(\n",
        "                                    current_timestamp\n",
        "                                )\n",
        "                                if last_backup_timestamp is None:\n",
        "                                    #print(f\"Criado backup do arquivo: {filename}\")\n",
        "                                    pass\n",
        "                                else:\n",
        "                                    print(f\"Atualizando backup do arquivo: {filename}\")\n",
        "                                updated = True\n",
        "                                fully_updated = False\n",
        "\n",
        "            for filepath in list(last_backup_timestamps.keys()):\n",
        "                if not os.path.exists(filepath):\n",
        "                    backup_filepath = os.path.join(\n",
        "                        GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER)\n",
        "                    )\n",
        "                    if os.path.exists(backup_filepath):\n",
        "                        os.remove(backup_filepath)\n",
        "                        print(f\"Arquivo deletado: {filepath}\")\n",
        "                    del last_backup_timestamps[filepath]\n",
        "                    updated = True\n",
        "                    fully_updated = False\n",
        "\n",
        "            if not updated and not fully_updated:\n",
        "                print(\"Arquivos estão atualizados.\")\n",
        "                fully_updated = True\n",
        "                sleep_time = 15\n",
        "            else:\n",
        "                sleep_time = 0.1\n",
        "\n",
        "            with open(last_backup_timestamps_path, \"w\") as f:\n",
        "                for filepath, timestamp in last_backup_timestamps.items():\n",
        "                    f.write(f\"{filepath}:{timestamp}\\n\")\n",
        "\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "        except Exception as error:\n",
        "            print(f\"Ocorreu um erro durante backup: {str(error)}\")\n",
        "\n",
        "\n",
        "if autobackups:\n",
        "    autobackups = False\n",
        "    print(\"Autobackup desativado\")\n",
        "else:\n",
        "    autobackups = True\n",
        "    print(\"Autobackup ativado\")\n",
        "\n",
        "total_de_epoch = 250  # @param {type:\"integer\"}\n",
        "batch_size = 16  # @param {type:\"slider\", min:1, max:25, step:0}\n",
        "gpu = 0\n",
        "orientação_de_pitch = True  # @param{type:\"boolean\"}\n",
        "auto_backups = True  # @param{type:\"boolean\"}\n",
        "pretrained = True\n",
        "sincronizar_graficos = False  # @param{type:\"boolean\"}\n",
        "dados_em_cache_na_gpu = False  # @param{type:\"boolean\"}\n",
        "tensorboard = True  # @param{type:\"boolean\"}\n",
        "# @markdown ### ➡️ Escolher de quantos em quantos Epochs seu modelo vai ser salvo\n",
        "salvar_a_cada_epoch = 10  # @param {type:\"slider\", min:1, max:100, step:0}\n",
        "salvar_somente_ultimo_G_e_D = True  # @param{type:\"boolean\"}\n",
        "salvar_cada_weights = True  # @param{type:\"boolean\"}\n",
        "detector_de_overtraining = False  # @param{type:\"boolean\"}\n",
        "limiar_do_overtraining = 50  # @param {type:\"slider\", min:1, max:100, step:0}\n",
        "# @markdown ### ➡️ Opcional\n",
        "# @markdown Se você quiser um pretreino customizado\n",
        "pretreino_customizado = False  # @param{type:\"boolean\"}\n",
        "pretreino_escolhido = \"Titan\" # @param [\"Titan\", \"Ov2\", \"Nanashi v1\", \"Nanashi v1.7\"] {allow-input: false}\n",
        "#@markdown ##### Os pretreino só estão disponiveis nos seguintes sample rates:\n",
        "#@markdown ##### **Titan:** 32k, 40k, 48k\n",
        "#@markdown ##### **Ov2:** 32k, 40k\n",
        "#@markdown ##### **Nanashi v1:** 32k\n",
        "#@markdown ##### **Nanashi v1.7:** 32k\n",
        "def baixar_modelos(pretreino_escolhido, sample_rate):\n",
        "    if pretreino_escolhido == \"Titan\":\n",
        "        if sample_rate == 32000:\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/32k/pretrained/G-f032k-TITAN-Medium.pth\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/32k/pretrained/D-f032k-TITAN-Medium.pth\n",
        "            g_pretrained_path = \"/content/Applio/G-f032k-TITAN-Medium.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/D-f032k-TITAN-Medium.pth\"\n",
        "        elif sample_rate == 40000:\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/40k/pretrained/G-f040k-TITAN-Medium.pth\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/40k/pretrained/D-f040k-TITAN-Medium.pth\n",
        "            g_pretrained_path = \"/content/Applio/G-f040k-TITAN-Medium.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/D-f040k-TITAN-Medium.pth\"\n",
        "        elif sample_rate == 48000:\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/G-f048k-TITAN-Medium.pth\n",
        "            !wget https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/D-f048k-TITAN-Medium.pth\n",
        "            g_pretrained_path = \"/content/Applio/G-f048k-TITAN-Medium.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/D-f048k-TITAN-Medium.pth\"\n",
        "    elif pretreino_escolhido == \"Ov2\":\n",
        "        if sample_rate == 32000:\n",
        "            !wget https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super32kG.pth\n",
        "            !wget https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super32kD.pth\n",
        "            g_pretrained_path = \"/content/Applio/f0Ov2Super32kG.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/f0Ov2Super32kD.pth\"\n",
        "        elif sample_rate == 40000:\n",
        "            !wget https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kG.pth\n",
        "            !wget https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kD.pth\n",
        "            g_pretrained_path = \"/content/Applio/f0Ov2Super40kG.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/f0Ov2Super40kD.pth\"\n",
        "        elif sample_rate == 48000:\n",
        "            raise RuntimeError(\"O Ov2 não tem sample rate de 48k, escolha outro pretreino\")\n",
        "    elif pretreino_escolhido == \"Nanashi v1\":\n",
        "        if sample_rate == 32000:\n",
        "            !wget https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1/G_nanashi_v1.pth\n",
        "            !wget https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1/D_nanashi_v1.pth\n",
        "            g_pretrained_path = \"/content/Applio/G_nanashi_v1.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/D_nanashi_v1.pth\"\n",
        "        elif sample_rate == 40000:\n",
        "            raise RuntimeError(\"O Nanashi v1 não tem sample rate de 40k, escolha outro pretreino\")\n",
        "        elif sample_rate == 48000:\n",
        "            raise RuntimeError(\"O Nanashi v1 não tem sample rate de 48k, escolha outro pretreino\")\n",
        "    elif pretreino_escolhido == \"Nanashi v1.7\":\n",
        "        if sample_rate == 32000:\n",
        "            !wget https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1.7/G_nanashi_v1_7.pth\n",
        "            !wget https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1.7/D_nanashi_v1_7.pth\n",
        "            g_pretrained_path = \"/content/Applio/G_nanashi_v1_7.pth\"\n",
        "            d_pretrained_path = \"/content/Applio/D_nanashi_v1_7.pth\"\n",
        "        elif sample_rate == 40000:\n",
        "            raise RuntimeError(\"O Nanashi v1.7 não tem sample rate de 40k, escolha outro pretreino\")\n",
        "        elif sample_rate == 48000:\n",
        "            raise RuntimeError(\"O Nanashi v1.7 não tem sample rate de 48k, escolha outro pretreino\")\n",
        "    else:\n",
        "        raise ValueError(\"Pretreino desconhecido\")\n",
        "\n",
        "if pretreino_customizado:\n",
        "    baixar_modelos(pretreino_escolhido, sample_rate)\n",
        "\n",
        "if \"pretrained\" not in globals():\n",
        "    pretrained = True\n",
        "\n",
        "if \"pretreino_customizado\" not in globals():\n",
        "    pretreino_customizado = False\n",
        "\n",
        "if \"g_pretrained_path\" not in globals():\n",
        "    g_pretrained_path = \"Custom Path\"\n",
        "\n",
        "if \"d_pretrained_path\" not in globals():\n",
        "    d_pretrained_path = \"Custom Path\"\n",
        "\n",
        "\n",
        "def start_train():\n",
        "    if tensorboard == True:\n",
        "        %load_ext tensorboard\n",
        "        %tensorboard --logdir /content/Applio/logs/\n",
        "    !python core.py train --model_name \"{nome_do_modelo}\" --rvc_version \"{versao_do_rvc}\" --save_every_epoch \"{salvar_a_cada_epoch}\" --save_only_latest \"{salvar_somente_ultimo_G_e_D}\" --save_every_weights \"{salvar_cada_weights}\" --total_epoch \"{total_de_epoch}\" --sample_rate \"{sample_rate}\" --batch_size \"{batch_size}\" --gpu \"{gpu}\" --pitch_guidance \"{orientação_de_pitch}\" --pretrained \"{pretrained}\" --custom_pretrained \"{pretreino_customizado}\" --g_pretrained_path \"{g_pretrained_path}\" --d_pretrained_path \"{d_pretrained_path}\" --overtraining_detector \"{detector_de_overtraining}\" --overtraining_threshold \"{limiar_do_overtraining}\" --sync_graph \"{sincronizar_graficos}\" --cache_data_in_gpu \"{dados_em_cache_na_gpu}\"\n",
        "\n",
        "\n",
        "server_thread = threading.Thread(target=start_train)\n",
        "server_thread.start()\n",
        "\n",
        "if auto_backups:\n",
        "    backup_files()\n",
        "else:\n",
        "    while True:\n",
        "        time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Go1XPCpu5UgX"
      },
      "outputs": [],
      "source": [
        "#@title ### Treinar o index\n",
        "!python core.py index --model_name \"{nome_do_modelo}\" --rvc_version \"{versao_do_rvc}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuar Treino"
      ],
      "metadata": {
        "id": "IEsgblUDSZLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Carregar Backup\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# @markdown Coloque o mesmo nome que colocou em nome do modelo\n",
        "nome_do_modelo = \"\"  # @param {type:\"string\"}\n",
        "source_path = \"/content/drive/MyDrive/RVC_Backup/\" + nome_do_modelo\n",
        "destination_path = \"/content/Applio/logs/\" + nome_do_modelo\n",
        "backup_timestamps_file = \"last_backup_timestamps.txt\"\n",
        "if not os.path.exists(source_path):\n",
        "    print(\n",
        "        \"The model folder does not exist. Please verify the name is correct or check your Google Drive.\"\n",
        "    )\n",
        "else:\n",
        "    time_ = os.path.join(\"/content/drive/MyDrive/RVC_Backup/\", backup_timestamps_file)\n",
        "    time__ = os.path.join(\"/content/Applio/logs/\", backup_timestamps_file)\n",
        "    if os.path.exists(time_):\n",
        "        shutil.copy(time_, time__)\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(\"Model backup loaded successfully.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WzZwBpKtSY1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Setar variaveis\n",
        "# @markdown ### ➡️ Use as mesmas configurações que usou antes\n",
        "model_name = \"\"  # @param {type:\"string\"}\n",
        "sample_rate = 32000  # @param [32000, 40000, 48000] {allow-input: false}\n",
        "rvc_version = \"v2\"  # @param [\"v2\", \"v1\"] {allow-input: false}\n",
        "f0_method = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\"] {allow-input: false}\n",
        "hop_length = 128  # @param {type:\"slider\", min:1, max:512, step:0}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "17Q7boWwTBEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}